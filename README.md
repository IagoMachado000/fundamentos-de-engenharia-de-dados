# Fundamentos de Engenharia de Dados
AnotaÃ§Ãµes sobre o curso Fundamentos de Engenharia de Dados https://www.datascienceacademy.com.br/course/fundamentos-de-engenharia-de-dados

Engenharia de dados Ã© a Ã¡rea da tecnologia responsÃ¡vel por **projetar, construir, manter e otimizar sistemas que coletam, armazenam, processam e disponibilizam dados** para anÃ¡lise e uso por outras Ã¡reas, como ciÃªncia de dados, BI (business intelligence) e engenharia de software.

### Em outras palavras:
O engenheiro de dados prepara os dados brutos â€” muitas vezes desorganizados, incompletos ou espalhados em vÃ¡rios lugares â€” e transforma isso em algo **organizado, limpo, acessÃ­vel e eficiente para anÃ¡lise**.

---

### Principais responsabilidades:
- **Coletar dados** de diversas fontes (bancos de dados, APIs, arquivos, etc.)
- **Criar pipelines de dados (ETL/ELT)** â€” processos que extraem, transformam e carregam dados para um destino final.
- **Modelar dados** para tornÃ¡-los mais Ãºteis e acessÃ­veis.
- **Garantir a qualidade dos dados** (dados limpos, consistentes e sem duplicidades).
- **Trabalhar com grandes volumes de dados** (Big Data).
- **Construir e gerenciar data lakes e data warehouses**.
- **Automatizar processos de ingestÃ£o e transformaÃ§Ã£o de dados**.
- **Implementar polÃ­ticas de seguranÃ§a e governanÃ§a de dados**.

---

### Tecnologias comuns na engenharia de dados:
- **Linguagens**: Python, SQL, Scala.
- **ETL/ELT**: Apache Airflow, dbt, Talend, Dataflow.
- **Big Data**: Apache Spark, Hadoop.
- **Bancos de dados**: PostgreSQL, MySQL, MongoDB, BigQuery, Snowflake, Redshift.
- **Armazenamento em nuvem**: AWS (S3, Glue), GCP (BigQuery, Cloud Storage), Azure.
- **Ferramentas de orquestraÃ§Ã£o e monitoramento**.

---

### DiferenÃ§a para outras Ã¡reas:
| Ãrea                | Foco principal                                           |
|---------------------|----------------------------------------------------------|
| **Engenharia de Dados** | Infraestrutura e organizaÃ§Ã£o dos dados                 |
| **CiÃªncia de Dados**     | AnÃ¡lise, prediÃ§Ã£o e criaÃ§Ã£o de modelos com os dados    |
| **BI (Business Intelligence)** | VisualizaÃ§Ã£o de dados para tomada de decisÃ£o        |
| **Engenharia de Software** | Desenvolvimento de sistemas e aplicativos             |

---

### GUIA DE ESTUDO E APRENDIZAGEM DA DATA SCIENCE ACADEMY 
[E-book](./pdf/49-E-book%20DSA%20_Guia_De_Estudo_Aprendizagem.pdf)

### Bibliografia, ReferÃªncias e Links Ãšteis
[Links](./pdf/10-BibliografiaCap01.pdf)

---

### Pipeline de dados

Um **pipeline de dados** Ã© como uma "linha de montagem" que **pega dados brutos de uma ou mais fontes, processa esses dados em etapas definidas e entrega o resultado pronto para ser usado** â€” geralmente em um banco de dados, data lake, data warehouse ou ferramenta de anÃ¡lise.

---

### Analogia simples:
Imagine que os dados sÃ£o grÃ£os de cafÃ©:

1. **ExtraÃ§Ã£o**: pegar os grÃ£os da plantaÃ§Ã£o (dados brutos).
2. **TransformaÃ§Ã£o**: torrar, moer, filtrar (limpar, organizar, juntar).
3. **Carga**: servir o cafÃ© na xÃ­cara (enviar os dados para o destino final).

Esse processo contÃ­nuo de **extraÃ§Ã£o, transformaÃ§Ã£o e carga** Ã© conhecido como **ETL (Extract, Transform, Load)** ou **ELT** (quando a transformaÃ§Ã£o vem depois da carga).

---

### Fases de um pipeline de dados:

1. **ExtraÃ§Ã£o (Extract)**  
   Captura dados de fontes diversas:
   - APIs
   - Bancos de dados
   - Arquivos CSV, Excel
   - ServiÃ§os de terceiros (como Google Analytics, Facebook Ads)

2. **TransformaÃ§Ã£o (Transform)**  
   Prepara os dados:
   - Limpeza (remover duplicatas, preencher valores ausentes)
   - ConversÃ£o de formatos
   - JunÃ§Ã£o de diferentes tabelas
   - AplicaÃ§Ã£o de regras de negÃ³cio

3. **Carga (Load)**  
   Envia os dados para o destino:
   - Banco relacional
   - Data warehouse (BigQuery, Redshift, Snowflake)
   - Data lake

---

### Exemplos de ferramentas de pipeline:

- **Apache Airflow** (orquestraÃ§Ã£o de tarefas e agendamentos)
- **dbt** (transformaÃ§Ãµes SQL em data warehouse)
- **Luigi**, **Prefect**, **Kedro** (orquestraÃ§Ã£o)
- **Talend**, **Informatica**, **AWS Glue**, **GCP Dataflow**

---

### Por que usar um pipeline?

- Automatiza o processo de movimentaÃ§Ã£o e tratamento de dados.
- Garante qualidade e consistÃªncia.
- Torna o fluxo de dados escalÃ¡vel e monitorÃ¡vel.
- Facilita a atualizaÃ§Ã£o de dados em tempo real ou agendada.

---

### Exemplo de um pipeline de dados

#### ğŸ§  CenÃ¡rio:
Temos um arquivo `usuarios.csv` com dados de usuÃ¡rios. Vamos:

1. **Extrair** os dados do CSV.  
2. **Transformar**: remover linhas com e-mails invÃ¡lidos.  
3. **Carregar**: salvar os dados limpos em um banco SQLite.

---

#### ğŸ“ Exemplo do CSV (`usuarios.csv`):

```csv
id,nome,email
1,Ana,ana@email.com
2,JoÃ£o,joao@email.com
3,Lucas,lucas@email
4,Marina,marina@email.com
```

> Note que o email do Lucas estÃ¡ invÃ¡lido (sem ".com").

---

#### ğŸ’» CÃ³digo do pipeline (`pipeline_etl.py`):

```python
import pandas as pd
import sqlite3
import re

# EXTRAÃ‡ÃƒO
def extrair_dados(caminho_csv):
    return pd.read_csv(caminho_csv)

# TRANSFORMAÃ‡ÃƒO
def limpar_dados(df):
    # Remove e-mails invÃ¡lidos com regex simples
    regex_email = r"[^@]+@[^@]+\.[^@]+"
    df_filtrado = df[df['email'].apply(lambda x: re.match(regex_email, x) is not None)]
    return df_filtrado

# CARGA
def carregar_dados(df, nome_banco):
    conn = sqlite3.connect(nome_banco)
    df.to_sql('usuarios', conn, if_exists='replace', index=False)
    conn.close()

# EXECUÃ‡ÃƒO DO PIPELINE
def pipeline():
    print("Iniciando pipeline...")
    dados = extrair_dados('usuarios.csv')
    print("ExtraÃ§Ã£o concluÃ­da!")

    dados_limpos = limpar_dados(dados)
    print("TransformaÃ§Ã£o concluÃ­da!")

    carregar_dados(dados_limpos, 'dados.db')
    print("Carga concluÃ­da! Dados salvos no banco 'dados.db'.")

if __name__ == "__main__":
    pipeline()
```

---

#### ğŸ“¦ Resultado:
- O pipeline cria um banco SQLite (`dados.db`) com uma tabela `usuarios` contendo **somente os registros vÃ¡lidos**.
- O Lucas serÃ¡ excluÃ­do por ter um e-mail invÃ¡lido.

---

### Componentes de um pipeline de dados

#### âœ… **1. Origem (Source)**  
SÃ£o os **locais onde os dados se encontram antes de serem processados**.

ğŸ”¹ **Componentes**:
- Bancos de dados relacionais (MySQL, PostgreSQL, SQL Server)
- Bancos NoSQL (MongoDB, Firebase, Cassandra)
- APIs (Google Ads, Facebook, Stripe, etc.)
- Arquivos (CSV, Excel, JSON, XML)
- Sistemas legados (ERP, CRM, etc.)
- Dados em tempo real (Kafka, IoT)

---

#### âš™ï¸ **2. Processamento (Processing)**  
Ã‰ o **coraÃ§Ã£o do pipeline**, onde os dados sÃ£o extraÃ­dos, tratados, organizados e preparados para o uso.

ğŸ”¹ **Componentes**:

##### A) **ExtraÃ§Ã£o (Extract)**  
- Captura os dados da origem.

##### B) **TransformaÃ§Ã£o (Transform)**  
- Limpeza, normalizaÃ§Ã£o, enriquecimento e padronizaÃ§Ã£o dos dados.

##### C) **OrquestraÃ§Ã£o e Agendamento**
- Coordena a ordem e o momento em que cada tarefa roda.
- Ferramentas: Apache Airflow, Prefect, Dagster

##### D) **ValidaÃ§Ã£o e Qualidade de Dados**
- Verifica se os dados estÃ£o consistentes e corretos.
- Regras de negÃ³cio, alertas e checagens.

##### E) **Monitoramento e Logs**
- Acompanha o status das execuÃ§Ãµes e detecta falhas.

---

#### ğŸ“¦ **3. Destino (Target)**  
Ã‰ onde os dados **processados sÃ£o armazenados e ficam prontos para uso** por sistemas, BI, machine learning, etc.

ğŸ”¹ **Componentes**:
- Data Warehouses (BigQuery, Redshift, Snowflake)
- Data Lakes (AWS S3, Azure Data Lake)
- Bancos SQL (PostgreSQL, MySQL)
- NoSQL (MongoDB, Elasticsearch)
- Dashboards de BI (Power BI, Looker, Tableau)
- Modelos de Machine Learning

---

#### ğŸ§  Visual Resumido:

```plaintext
[ ORIGEM ]
    â†“
[ EXTRAÃ‡ÃƒO ]
    â†“
[ TRANSFORMAÃ‡ÃƒO ]
    â†“
[ CARGA ]
    â†“
[ DESTINO ]
    â†“
[ CONSUMO (dashboards, anÃ¡lises, ML, etc.) ]
```

---

### Pipeline de dados x pipeline ETL

Pipeline de dados e pipeline ETL **nem sempre sÃ£o a mesma coisa**, mas muitas vezes sÃ£o usados como **sinÃ´nimos** â€” especialmente em contextos mais simples.

Vamos ver a diferenÃ§a com clareza:

---

#### âœ… **Pipeline ETL** (Extract, Transform, Load)

Ã‰ um tipo especÃ­fico de pipeline de dados que segue **trÃªs etapas principais**:

1. **Extract (ExtraÃ§Ã£o)** â€“ pega dados brutos de uma ou mais fontes.  
2. **Transform (TransformaÃ§Ã£o)** â€“ limpa, trata e padroniza os dados.  
3. **Load (Carga)** â€“ envia os dados para um destino (ex: data warehouse).

ğŸ”¹ Muito usado quando o foco estÃ¡ em **mover e preparar dados para anÃ¡lises** ou BI.

---

#### ğŸ”„ **Pipeline de Dados** (Data Pipeline)

Ã‰ um termo **mais genÃ©rico e abrangente**.

Pode incluir:

- Pipelines ETL (ou ELT)
- Pipelines de streaming (dados em tempo real)
- Pipelines de machine learning (com ingestÃ£o, treino de modelo, deploy)
- Pipelines de replicaÃ§Ã£o de dados
- Pipelines de integraÃ§Ã£o contÃ­nua com dados

Ou seja, **todo pipeline ETL Ã© um pipeline de dados**, mas **nem todo pipeline de dados Ã© ETL**.

---

#### ğŸ’¡ Exemplo de diferenÃ§a:

- **Pipeline ETL**: Extrai dados do MySQL, transforma em pandas, carrega no BigQuery.
- **Pipeline de streaming**: Usa Kafka + Spark para processar dados de sensores em tempo real.
- **Pipeline de ML**: Coleta dados, transforma, treina modelo, gera previsÃµes automaticamente.

---

#### ğŸ§  Resumindo:
| Termo              | AbrangÃªncia | Finalidade principal           |
|--------------------|-------------|--------------------------------|
| **Pipeline ETL**   | Mais especÃ­fico | MovimentaÃ§Ã£o + tratamento de dados |
| **Pipeline de Dados** | Mais amplo     | Qualquer fluxo automatizado de dados |

---

### Principais ferramentas para construir pipeline de dados

#### ğŸ” 1. TransformaÃ§Ã£o de Dados

#### O que Ã©:
SÃ£o ferramentas que **tratam, limpam, enriquecem, organizam e preparam os dados** para uso â€” geralmente apÃ³s a extraÃ§Ã£o e antes do carregamento final.

#### Tarefas comuns:
- Padronizar nomes de colunas
- Corrigir valores inconsistentes
- Juntar dados de diferentes fontes
- Agregar mÃ©tricas (ex: soma de vendas por dia)

#### Ferramentas populares:
| Ferramenta     | DescriÃ§Ã£o breve |
|----------------|------------------|
| **dbt (Data Build Tool)** | Transforma dados usando SQL diretamente no data warehouse. Ideal para times de analytics. |
| **Apache Spark** | Processa grandes volumes de dados em cluster (paralelo), com suporte a batch e streaming. |
| **Pandas (Python)** | Biblioteca poderosa para transformar dados tabulares em notebooks/scripts. Ã“tima para prototipaÃ§Ã£o. |
| **Apache Beam** | Framework de transformaÃ§Ã£o com suporte a batch e streaming. Roda em Dataflow (GCP), Spark, Flink, etc. |
| **Airbyte / Fivetran / Talend** | Algumas dessas ferramentas tambÃ©m permitem transformaÃ§Ãµes, alÃ©m da extraÃ§Ã£o/carga. |

---

#### â˜ï¸ 2. Armazenamento e Cloud Computing

#### O que Ã©:
SÃ£o os **locais onde os dados sÃ£o armazenados**, organizados e disponibilizados â€” muitas vezes em nuvem. TambÃ©m inclui serviÃ§os que **escalam automaticamente**, como clusters, servidores e bancos gerenciados.

#### SubdivisÃµes:
- **Data warehouses** (anÃ¡lises)
- **Data lakes** (armazenamento bruto)
- **Bancos relacionais/NoSQL**
- **Infraestrutura em nuvem (IaaS/PaaS)**

#### Ferramentas populares:
| Ferramenta     | DescriÃ§Ã£o breve |
|----------------|------------------|
| **Google BigQuery** | Data warehouse serverless da GCP, ideal para grandes volumes e consultas rÃ¡pidas. |
| **Amazon Redshift** | Data warehouse da AWS, otimizado para anÃ¡lises massivas. |
| **Snowflake** | Data warehouse multi-cloud, altamente escalÃ¡vel. |
| **AWS S3** | Armazena arquivos em nuvem (data lake). |
| **Azure Data Lake** | Equivalente ao S3 na Azure. |
| **Databricks** | Plataforma para engenharia e ciÃªncia de dados baseada em Spark. |
| **Google Cloud Platform / AWS / Azure** | Provedores cloud com serviÃ§os integrados de dados, computaÃ§Ã£o, seguranÃ§a, etc. |

---

#### âš¡ 3. Real-Time Analytics (AnÃ¡lise em Tempo Real)

#### O que Ã©:
SÃ£o ferramentas e plataformas voltadas para **ingestÃ£o, processamento e anÃ¡lise de dados em tempo real ou quase tempo real**. Ideal para sistemas que precisam de respostas imediatas (ex: detecÃ§Ã£o de fraudes, monitoramento de sensores, logs).

#### Ferramentas populares:
| Ferramenta     | DescriÃ§Ã£o breve |
|----------------|------------------|
| **Apache Kafka** | Sistema de mensageria distribuÃ­do, ideal para capturar e transmitir eventos em tempo real. |
| **Apache Flink** | Processamento de dados em streaming com baixa latÃªncia. |
| **Apache Spark Structured Streaming** | MÃ³dulo do Spark para trabalhar com dados em tempo real. |
| **Google Dataflow** | ServiÃ§o de stream/batch processing na GCP, baseado em Apache Beam. |
| **Kinesis (AWS)** | Equivalente ao Kafka na AWS, ideal para ingestÃ£o de dados em tempo real. |
| **ClickHouse** | Banco OLAP de alta performance, muito usado para analytics em tempo real. |

---

#### ğŸ’¡ Resumo visual da classificaÃ§Ã£o:

```plaintext
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TransformaÃ§Ã£o de Dados    â”‚  â† limpeza, preparo, junÃ§Ãµes
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  dbt, Spark, Pandas, Beam  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Armazenamento e Cloud       â”‚  â† onde os dados sÃ£o guardados
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  BigQuery, Redshift, S3,     â”‚
â”‚  Snowflake, Databricks       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Real-Time Analytics       â”‚  â† dados em tempo real
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Kafka, Flink, Dataflow,   â”‚
â”‚  Spark Streaming, Kinesis  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

