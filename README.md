# Fundamentos de Engenharia de Dados
Anota√ß√µes sobre o curso Fundamentos de Engenharia de Dados https://www.datascienceacademy.com.br/course/fundamentos-de-engenharia-de-dados

Engenharia de dados √© a √°rea da tecnologia respons√°vel por **projetar, construir, manter e otimizar sistemas que coletam, armazenam, processam e disponibilizam dados** para an√°lise e uso por outras √°reas, como ci√™ncia de dados, BI (business intelligence) e engenharia de software.

### Em outras palavras:
O engenheiro de dados prepara os dados brutos ‚Äî muitas vezes desorganizados, incompletos ou espalhados em v√°rios lugares ‚Äî e transforma isso em algo **organizado, limpo, acess√≠vel e eficiente para an√°lise**.

---

### Principais responsabilidades:
- **Coletar dados** de diversas fontes (bancos de dados, APIs, arquivos, etc.)
- **Criar pipelines de dados (ETL/ELT)** ‚Äî processos que extraem, transformam e carregam dados para um destino final.
- **Modelar dados** para torn√°-los mais √∫teis e acess√≠veis.
- **Garantir a qualidade dos dados** (dados limpos, consistentes e sem duplicidades).
- **Trabalhar com grandes volumes de dados** (Big Data).
- **Construir e gerenciar data lakes e data warehouses**.
- **Automatizar processos de ingest√£o e transforma√ß√£o de dados**.
- **Implementar pol√≠ticas de seguran√ßa e governan√ßa de dados**.

---

### Tecnologias comuns na engenharia de dados:
- **Linguagens**: Python, SQL, Scala.
- **ETL/ELT**: Apache Airflow, dbt, Talend, Dataflow.
- **Big Data**: Apache Spark, Hadoop.
- **Bancos de dados**: PostgreSQL, MySQL, MongoDB, BigQuery, Snowflake, Redshift.
- **Armazenamento em nuvem**: AWS (S3, Glue), GCP (BigQuery, Cloud Storage), Azure.
- **Ferramentas de orquestra√ß√£o e monitoramento**.

---

### Diferen√ßa para outras √°reas:
| √Årea                | Foco principal                                           |
|---------------------|----------------------------------------------------------|
| **Engenharia de Dados** | Infraestrutura e organiza√ß√£o dos dados                 |
| **Ci√™ncia de Dados**     | An√°lise, predi√ß√£o e cria√ß√£o de modelos com os dados    |
| **BI (Business Intelligence)** | Visualiza√ß√£o de dados para tomada de decis√£o        |
| **Engenharia de Software** | Desenvolvimento de sistemas e aplicativos             |

---

### GUIA DE ESTUDO E APRENDIZAGEM DA DATA SCIENCE ACADEMY 
[E-book](./pdf/49-E-book%20DSA%20_Guia_De_Estudo_Aprendizagem.pdf)

### Bibliografia, Refer√™ncias e Links √öteis
[Links](./pdf/10-BibliografiaCap01.pdf)

---

### Pipeline de dados

Um **pipeline de dados** √© como uma "linha de montagem" que **pega dados brutos de uma ou mais fontes, processa esses dados em etapas definidas e entrega o resultado pronto para ser usado** ‚Äî geralmente em um banco de dados, data lake, data warehouse ou ferramenta de an√°lise.

---

### Analogia simples:
Imagine que os dados s√£o gr√£os de caf√©:

1. **Extra√ß√£o**: pegar os gr√£os da planta√ß√£o (dados brutos).
2. **Transforma√ß√£o**: torrar, moer, filtrar (limpar, organizar, juntar).
3. **Carga**: servir o caf√© na x√≠cara (enviar os dados para o destino final).

Esse processo cont√≠nuo de **extra√ß√£o, transforma√ß√£o e carga** √© conhecido como **ETL (Extract, Transform, Load)** ou **ELT** (quando a transforma√ß√£o vem depois da carga).

---

### Fases de um pipeline de dados:

1. **Extra√ß√£o (Extract)**  
   Captura dados de fontes diversas:
   - APIs
   - Bancos de dados
   - Arquivos CSV, Excel
   - Servi√ßos de terceiros (como Google Analytics, Facebook Ads)

2. **Transforma√ß√£o (Transform)**  
   Prepara os dados:
   - Limpeza (remover duplicatas, preencher valores ausentes)
   - Convers√£o de formatos
   - Jun√ß√£o de diferentes tabelas
   - Aplica√ß√£o de regras de neg√≥cio

3. **Carga (Load)**  
   Envia os dados para o destino:
   - Banco relacional
   - Data warehouse (BigQuery, Redshift, Snowflake)
   - Data lake

---

### Exemplos de ferramentas de pipeline:

- **Apache Airflow** (orquestra√ß√£o de tarefas e agendamentos)
- **dbt** (transforma√ß√µes SQL em data warehouse)
- **Luigi**, **Prefect**, **Kedro** (orquestra√ß√£o)
- **Talend**, **Informatica**, **AWS Glue**, **GCP Dataflow**

---

### Por que usar um pipeline?

- Automatiza o processo de movimenta√ß√£o e tratamento de dados.
- Garante qualidade e consist√™ncia.
- Torna o fluxo de dados escal√°vel e monitor√°vel.
- Facilita a atualiza√ß√£o de dados em tempo real ou agendada.

---

### Exemplo de um pipeline de dados

#### üß† Cen√°rio:
Temos um arquivo `usuarios.csv` com dados de usu√°rios. Vamos:

1. **Extrair** os dados do CSV.  
2. **Transformar**: remover linhas com e-mails inv√°lidos.  
3. **Carregar**: salvar os dados limpos em um banco SQLite.

---

#### üìÅ Exemplo do CSV (`usuarios.csv`):

```csv
id,nome,email
1,Ana,ana@email.com
2,Jo√£o,joao@email.com
3,Lucas,lucas@email
4,Marina,marina@email.com
```

> Note que o email do Lucas est√° inv√°lido (sem ".com").

---

#### üíª C√≥digo do pipeline (`pipeline_etl.py`):

```python
import pandas as pd
import sqlite3
import re

# EXTRA√á√ÉO
def extrair_dados(caminho_csv):
    return pd.read_csv(caminho_csv)

# TRANSFORMA√á√ÉO
def limpar_dados(df):
    # Remove e-mails inv√°lidos com regex simples
    regex_email = r"[^@]+@[^@]+\.[^@]+"
    df_filtrado = df[df['email'].apply(lambda x: re.match(regex_email, x) is not None)]
    return df_filtrado

# CARGA
def carregar_dados(df, nome_banco):
    conn = sqlite3.connect(nome_banco)
    df.to_sql('usuarios', conn, if_exists='replace', index=False)
    conn.close()

# EXECU√á√ÉO DO PIPELINE
def pipeline():
    print("Iniciando pipeline...")
    dados = extrair_dados('usuarios.csv')
    print("Extra√ß√£o conclu√≠da!")

    dados_limpos = limpar_dados(dados)
    print("Transforma√ß√£o conclu√≠da!")

    carregar_dados(dados_limpos, 'dados.db')
    print("Carga conclu√≠da! Dados salvos no banco 'dados.db'.")

if __name__ == "__main__":
    pipeline()
```

---

#### üì¶ Resultado:
- O pipeline cria um banco SQLite (`dados.db`) com uma tabela `usuarios` contendo **somente os registros v√°lidos**.
- O Lucas ser√° exclu√≠do por ter um e-mail inv√°lido.

---

### Componentes de um pipeline de dados

#### ‚úÖ **1. Origem (Source)**  
S√£o os **locais onde os dados se encontram antes de serem processados**.

üîπ **Componentes**:
- Bancos de dados relacionais (MySQL, PostgreSQL, SQL Server)
- Bancos NoSQL (MongoDB, Firebase, Cassandra)
- APIs (Google Ads, Facebook, Stripe, etc.)
- Arquivos (CSV, Excel, JSON, XML)
- Sistemas legados (ERP, CRM, etc.)
- Dados em tempo real (Kafka, IoT)

---

#### ‚öôÔ∏è **2. Processamento (Processing)**  
√â o **cora√ß√£o do pipeline**, onde os dados s√£o extra√≠dos, tratados, organizados e preparados para o uso.

üîπ **Componentes**:

##### A) **Extra√ß√£o (Extract)**  
- Captura os dados da origem.

##### B) **Transforma√ß√£o (Transform)**  
- Limpeza, normaliza√ß√£o, enriquecimento e padroniza√ß√£o dos dados.

##### C) **Orquestra√ß√£o e Agendamento**
- Coordena a ordem e o momento em que cada tarefa roda.
- Ferramentas: Apache Airflow, Prefect, Dagster

##### D) **Valida√ß√£o e Qualidade de Dados**
- Verifica se os dados est√£o consistentes e corretos.
- Regras de neg√≥cio, alertas e checagens.

##### E) **Monitoramento e Logs**
- Acompanha o status das execu√ß√µes e detecta falhas.

---

#### üì¶ **3. Destino (Target)**  
√â onde os dados **processados s√£o armazenados e ficam prontos para uso** por sistemas, BI, machine learning, etc.

üîπ **Componentes**:
- Data Warehouses (BigQuery, Redshift, Snowflake)
- Data Lakes (AWS S3, Azure Data Lake)
- Bancos SQL (PostgreSQL, MySQL)
- NoSQL (MongoDB, Elasticsearch)
- Dashboards de BI (Power BI, Looker, Tableau)
- Modelos de Machine Learning

---

#### üß† Visual Resumido:

```plaintext
[ ORIGEM ]
    ‚Üì
[ EXTRA√á√ÉO ]
    ‚Üì
[ TRANSFORMA√á√ÉO ]
    ‚Üì
[ CARGA ]
    ‚Üì
[ DESTINO ]
    ‚Üì
[ CONSUMO (dashboards, an√°lises, ML, etc.) ]
```

---

### Pipeline de dados x pipeline ETL

Pipeline de dados e pipeline ETL **nem sempre s√£o a mesma coisa**, mas muitas vezes s√£o usados como **sin√¥nimos** ‚Äî especialmente em contextos mais simples.

Vamos ver a diferen√ßa com clareza:

---

#### ‚úÖ **Pipeline ETL** (Extract, Transform, Load)

√â um tipo espec√≠fico de pipeline de dados que segue **tr√™s etapas principais**:

1. **Extract (Extra√ß√£o)** ‚Äì pega dados brutos de uma ou mais fontes.  
2. **Transform (Transforma√ß√£o)** ‚Äì limpa, trata e padroniza os dados.  
3. **Load (Carga)** ‚Äì envia os dados para um destino (ex: data warehouse).

üîπ Muito usado quando o foco est√° em **mover e preparar dados para an√°lises** ou BI.

---

#### üîÑ **Pipeline de Dados** (Data Pipeline)

√â um termo **mais gen√©rico e abrangente**.

Pode incluir:

- Pipelines ETL (ou ELT)
- Pipelines de streaming (dados em tempo real)
- Pipelines de machine learning (com ingest√£o, treino de modelo, deploy)
- Pipelines de replica√ß√£o de dados
- Pipelines de integra√ß√£o cont√≠nua com dados

Ou seja, **todo pipeline ETL √© um pipeline de dados**, mas **nem todo pipeline de dados √© ETL**.

---

#### üí° Exemplo de diferen√ßa:

- **Pipeline ETL**: Extrai dados do MySQL, transforma em pandas, carrega no BigQuery.
- **Pipeline de streaming**: Usa Kafka + Spark para processar dados de sensores em tempo real.
- **Pipeline de ML**: Coleta dados, transforma, treina modelo, gera previs√µes automaticamente.

---

#### üß† Resumindo:
| Termo              | Abrang√™ncia | Finalidade principal           |
|--------------------|-------------|--------------------------------|
| **Pipeline ETL**   | Mais espec√≠fico | Movimenta√ß√£o + tratamento de dados |
| **Pipeline de Dados** | Mais amplo     | Qualquer fluxo automatizado de dados |

---

### Principais ferramentas para construir pipeline de dados

#### üîÅ 1. Transforma√ß√£o de Dados

#### O que √©:
S√£o ferramentas que **tratam, limpam, enriquecem, organizam e preparam os dados** para uso ‚Äî geralmente ap√≥s a extra√ß√£o e antes do carregamento final.

#### Tarefas comuns:
- Padronizar nomes de colunas
- Corrigir valores inconsistentes
- Juntar dados de diferentes fontes
- Agregar m√©tricas (ex: soma de vendas por dia)

#### Ferramentas populares:
| Ferramenta     | Descri√ß√£o breve |
|----------------|------------------|
| **dbt (Data Build Tool)** | Transforma dados usando SQL diretamente no data warehouse. Ideal para times de analytics. |
| **Apache Spark** | Processa grandes volumes de dados em cluster (paralelo), com suporte a batch e streaming. |
| **Pandas (Python)** | Biblioteca poderosa para transformar dados tabulares em notebooks/scripts. √ìtima para prototipa√ß√£o. |
| **Apache Beam** | Framework de transforma√ß√£o com suporte a batch e streaming. Roda em Dataflow (GCP), Spark, Flink, etc. |
| **Airbyte / Fivetran / Talend** | Algumas dessas ferramentas tamb√©m permitem transforma√ß√µes, al√©m da extra√ß√£o/carga. |

---

#### ‚òÅÔ∏è 2. Armazenamento e Cloud Computing

#### O que √©:
S√£o os **locais onde os dados s√£o armazenados**, organizados e disponibilizados ‚Äî muitas vezes em nuvem. Tamb√©m inclui servi√ßos que **escalam automaticamente**, como clusters, servidores e bancos gerenciados.

#### Subdivis√µes:
- **Data warehouses** (an√°lises)
- **Data lakes** (armazenamento bruto)
- **Bancos relacionais/NoSQL**
- **Infraestrutura em nuvem (IaaS/PaaS)**

#### Ferramentas populares:
| Ferramenta     | Descri√ß√£o breve |
|----------------|------------------|
| **Google BigQuery** | Data warehouse serverless da GCP, ideal para grandes volumes e consultas r√°pidas. |
| **Amazon Redshift** | Data warehouse da AWS, otimizado para an√°lises massivas. |
| **Snowflake** | Data warehouse multi-cloud, altamente escal√°vel. |
| **AWS S3** | Armazena arquivos em nuvem (data lake). |
| **Azure Data Lake** | Equivalente ao S3 na Azure. |
| **Databricks** | Plataforma para engenharia e ci√™ncia de dados baseada em Spark. |
| **Google Cloud Platform / AWS / Azure** | Provedores cloud com servi√ßos integrados de dados, computa√ß√£o, seguran√ßa, etc. |

---

#### ‚ö° 3. Real-Time Analytics (An√°lise em Tempo Real)

#### O que √©:
S√£o ferramentas e plataformas voltadas para **ingest√£o, processamento e an√°lise de dados em tempo real ou quase tempo real**. Ideal para sistemas que precisam de respostas imediatas (ex: detec√ß√£o de fraudes, monitoramento de sensores, logs).

#### Ferramentas populares:
| Ferramenta     | Descri√ß√£o breve |
|----------------|------------------|
| **Apache Kafka** | Sistema de mensageria distribu√≠do, ideal para capturar e transmitir eventos em tempo real. |
| **Apache Flink** | Processamento de dados em streaming com baixa lat√™ncia. |
| **Apache Spark Structured Streaming** | M√≥dulo do Spark para trabalhar com dados em tempo real. |
| **Google Dataflow** | Servi√ßo de stream/batch processing na GCP, baseado em Apache Beam. |
| **Kinesis (AWS)** | Equivalente ao Kafka na AWS, ideal para ingest√£o de dados em tempo real. |
| **ClickHouse** | Banco OLAP de alta performance, muito usado para analytics em tempo real. |

---

#### üí° Resumo visual da classifica√ß√£o:

```plaintext
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Transforma√ß√£o de Dados    ‚îÇ  ‚Üê limpeza, preparo, jun√ß√µes
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  dbt, Spark, Pandas, Beam  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Armazenamento e Cloud       ‚îÇ  ‚Üê onde os dados s√£o guardados
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  BigQuery, Redshift, S3,     ‚îÇ
‚îÇ  Snowflake, Databricks       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Real-Time Analytics       ‚îÇ  ‚Üê dados em tempo real
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Kafka, Flink, Dataflow,   ‚îÇ
‚îÇ  Spark Streaming, Kinesis  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

